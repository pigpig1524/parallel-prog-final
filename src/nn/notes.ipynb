{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaff2bf0",
   "metadata": {},
   "source": [
    "### Phần 1:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1178f2ca",
   "metadata": {},
   "source": [
    "### Phần 2:\n",
    "##### Chuyển dữ liệu host ↔ device:\n",
    "Host đưa input cho device. Device xử lí trong nội bộ và trả về output cho host. Vậy ta sẽ có các hàm cudaMemcpy để thực hiện các tác vụ:  \n",
    "+ chuyển input từ host sang device  \n",
    "+ Khởi tạo các trọng số cho mô hình sẽ được thực hiện trên host rồi chuyển sang device.\n",
    "+ Chuyển output từ device sang host\n",
    "+ Chuyển giá trị hàm loss từ device sang host để giám sát quá trình huấn luyện mô hình.\n",
    "\n",
    "##### Phần tổ chức dữ liệu cho kernel:\n",
    "Như ta đã biết thì dữ liệu lưu theo index của `threadIdx`, `blockDim`, `blockIdx` chỉ có 3 chiều (x, y, z), trong khi đó, dữ liệu mà ta đang xử lí có tới 4 chiều (H, W, Channel, Batch). Ý tưởng của nhóm em là gộp chiều Channel với Batch lại và lưu và chiều z. Khi đó, một dữ liệu input có chiều (x,y,c,b):\n",
    "$$\\begin{align}\n",
    "\\text{flat\\_index} &= (b \\cdot C + c) \\cdot H \\cdot W + W \\cdot h + w \\\\\n",
    "&= ((b \\cdot C + c) \\cdot H + h) \\cdot W + w\n",
    "\\end{align}$$\n",
    "\n",
    "##### Tại sao trên các kernel ReLU lại chỉ sử dụng 1 chiều x trong khi các kernel khác thì sử dụng tới 3 chiều ?\n",
    "\n",
    "##### Tại sao index của chiều batch-channel lại được biểu diễn qua blockIdx.z mà không phải là blockIdx.z * blockDim.z + threadIdx.z ?\n",
    "\n",
    "\n",
    "##### Tại sao ko cần cudaDeviceSynchronize() sau mỗi kernel call trong forwardPass ?\n",
    "Vì tất cả job đều nằm trên cùng 1 stream 0 nên các hàm được nằm ở trước chắc chắn sẽ được thực hiện trước.\n",
    "\n",
    "\n",
    "##### Thắc mắc về vấn đề đo thời gian kernel:\n",
    "1. Tại sao ta phải sử dụng lambda function cho đoạn code ?\n",
    "```c++\n",
    "measureKernelTime([&]() {\n",
    "        k_conv2d_forward<<<grid, block>>>(d_input, d_w_enc_conv1, d_b_enc_conv1, d_enc_conv1, inC, outC, H_in, W_in, filterWidth, padding, stride);\n",
    "    }, conv_forward_time, \"Conv2D Forward\");\n",
    "```\n",
    "Vì:\n",
    "Immediate execution: When you write the kernel launch directly as a parameter, it gets executed immediately when the function arguments are evaluated, before measureKernelTime even starts running\n",
    "\n",
    "\n",
    "##### Tại sao backward lại lâu nhất ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437f278b",
   "metadata": {},
   "source": [
    "##### Khó khăn:\n",
    "Trong quá trình train, liên tục bị gradient explosion nên đã áp dụng gradient clipping cho backprop ổn định hơn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2342d58d",
   "metadata": {},
   "source": [
    "#### Cải tiến:\n",
    "\n",
    "##### Apply shared memory cho kernel backprop cho các weight:\n",
    "Ý tưởng: Mỗi thread xử lí một backprop cho một output. Từ một output xác định (ob, oc, oh, ow), ta thực hiện backprop cho từng filter thuộc từng channel bằng cách \n",
    "nhân grad với các input tương ứng.  \n",
    "- First approach: Sử dụng memory để load toàn bộ tensor 3 chiều của input ứng với output mà thread đang xử lí.\n",
    "-> Bị tràn shared mem khi blockSize = 32. fail silently -> tốn rất nhiều thời gian mới phát hiện ra\n",
    "- Second approach: Chia ra xử lí từng channel input\n",
    "-> good\n",
    "\n",
    "##### Apply shared memory cho kernel backprop input:\n",
    "Ý tưởng: Mỗi threadd xử lí backprop cho một input. Từ một input xác định (ib, ic, ih, iw), ta xác định ra các output mà input đó có đóng góp và thực hiện backprop \n",
    "bằng cách nhân grad với các weight tương ứng"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
